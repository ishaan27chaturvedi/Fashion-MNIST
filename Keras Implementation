{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2NPAI4jZZgi"
   },
   "source": [
    "# Modern Deep Learning: \n",
    "# Classify Fashion-MNIST with a simple CNN in Keras\n",
    "\n",
    "Original version from https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a, adapted & extended by Xander Steenbrugge.\n",
    "![alt text](https://github.com/margaretmz/deep-learning/blob/master/images/modern%20dl_fash-mnist_keras.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "18xLQCydFHqi"
   },
   "source": [
    "## Why Jupyter Notebook?\n",
    "\n",
    "\n",
    "*   Interactive programming in the web browser\n",
    "*   Great for visualization\n",
    "*   Great for collabration\n",
    "*   Popular tool for studying machine learning / deep learning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XLMRPLVCFwEc"
   },
   "source": [
    "## Why Fashion-MNIST?\n",
    "\n",
    "\n",
    "*   MNIST is too easy\n",
    "*   MNIST is overused\n",
    "*   MNIST can not represent modern Computer Vision tasks\n",
    "\n",
    "Read more about the Fashion-MINST dataset in this paper [here](https://arxiv.org/abs/1708.07747) (**Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ixyte299ZZgk"
   },
   "source": [
    "## Notebook Overview\n",
    "\n",
    "This is a tutorial of how to classify **fashion_mnist** data with a simple **Convolutional Neural Network** in Keras. \n",
    "Keras is now part of the core TensorFlow library, in addition to being an independent open source project. \n",
    "\n",
    "We will work our way to an efficiently regularized, convolutional network in small, incremental steps, starting from a simple, linear model and gradually adding more and more complexity to our neural network.\n",
    "\n",
    "\n",
    "The [fashion_mnist](https://github.com/zalandoresearch/fashion-mnist) data: \n",
    "60,000 train and 10,000 test data with 10 categories. Each gray-scale image is 28x28.\n",
    "\n",
    "<br> **Label**\t**Description**\n",
    "<br> 0 T-shirt/top\n",
    "<br> 1 Trouser\n",
    "<br> 2 Pullover\n",
    "<br> 3 Dress\n",
    "<br> 4 Coat\n",
    "<br> 5 Sandal\n",
    "<br> 6 Shirt\n",
    "<br> 7 Sneaker\n",
    "<br> 8 Bag\n",
    "<br> 9 Ankle boot\n",
    "\n",
    "Each gray-scale image is 28x28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "First, install TensorFlow version 1.8.0 and import the Fashion-MNIST dataset\n",
    "We will also be using numpy, matplotlib and the native Keras package, so install those if you haven't already!\n",
    "\n",
    "Check the requirements.txt file for all necessary dependencies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test your imports:\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LbCigZtNZZgl"
   },
   "source": [
    "## 1.0 Download the fashion_mnist data\n",
    "Now, let's download fashion-mnist which is one of the Keras datasets: https://keras.io/datasets/\n",
    "Pull the dataset from disk into cache memory by storing it in numpy arrays.\n",
    "As a sanity check, print some shapes to make sure everything is as expected! You should have images of 28 by 28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "d44TznbgZZgm",
    "outputId": "b722a31e-6c74-45d1-b07c-4bafb4c29a60"
   },
   "outputs": [],
   "source": [
    "# Load the fashion-mnist pre-shuffled train data and test data\n",
    "(x_train_data, y_train_data), (x_test_data, y_test_data) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# Define the text labels:\n",
    "dataset_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "#Print some shapes of the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWORMSC8FDR4"
   },
   "source": [
    "## 1.1 Visualize the data\n",
    "Before we start defining any models, lets have a look at our data to get a sense of what we're dealing with.\n",
    "Use matplotlib to visualise some of the training images, can you identify the classes yourself?\n",
    "Perhaps create a simple, callable function that plots a dataset image, given its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "aFe4wHGRFKle",
    "outputId": "76e7edaa-60db-4cad-c567-277013795a8c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zx-Ee6LHZZgt"
   },
   "source": [
    "## 1.2 Data normalization\n",
    "First investigate the range of the pixel values in the images: what are the min and max you find?\n",
    "\n",
    "For a neural network to work well, we want these pixel values to be within the range 0-1. Rescale the image pixel values to make this so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNh5NIckZZgu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFlNHktHBtru"
   },
   "source": [
    "## 1.3 Split the data into train/validation/test data sets\n",
    "In Machine Learning, we always want to be able to validate how well our model is doing on data it hasn't yet trained on.\n",
    "\n",
    "*   Training data - used for training the model\n",
    "*   Validation data - used for tuning the hyperparameters and evaluate the models\n",
    "*   Test data - used to test the model after the model has gone through initial vetting by the validation set.\n",
    "\n",
    "Split off 10% of the training data and put this into the validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_fraction = .1\n",
    "\n",
    "## ToDo ##\n",
    "\n",
    "(x_train, x_valid) = \n",
    "(y_train, y_valid) = \n",
    "(x_test, y_test) = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Some final preprocessing\n",
    "Most image datasets consist of rgb images. Because of this, Keras will expect each image to have 3 dimensions: [x_pixels, y_pixels, color_channels]. Since our images are grayscale, the color dimension is equal to one and implicitly left out in the numpy arrays. Reshape the image data to contain an explicit color channel of dimension 1. (Your final numpy arrays should have the dimension [nr_samples, x_pixels, y_pixels, 1].)\n",
    "\n",
    "Secondly, it is very common in deep learning to do classification tasks. To train our model, we will use the categorical crossentropy loss (see https://keras.io/losses/). To compute this, we have to format our image labels as one-hot-vectors. The easiest way to do this is with the tf.keras.utils.to_categorical() function, see: https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "1ShU787gZZg0",
    "outputId": "2016e59c-a88b-4ecd-c9fa-1177011877d1"
   },
   "outputs": [],
   "source": [
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "\n",
    "#Reshape the data:\n",
    "\n",
    "#One-hot encode the labels:\n",
    "\n",
    "#Print some shapes for sanity checking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HhalcO03ZZg3"
   },
   "source": [
    "# 2 Creating a model\n",
    "\n",
    "There are two APIs for defining a model in Keras:\n",
    "1. [Sequential model API](https://keras.io/models/sequential/)\n",
    "2. [Functional API](https://keras.io/models/model/)\n",
    "\n",
    "In this notebook we are using the Sequential model API. \n",
    "If you are interested in a tutorial using the Functional API, checkout Sara Robinson's blog [Predicting the price of wine with the Keras Functional API and TensorFlow](https://medium.com/tensorflow/predicting-the-price-of-wine-with-the-keras-functional-api-and-tensorflow-a95d1c2c1b03).\n",
    "\n",
    "In defining the models today, we will be using some of these Keras APIs: (you can check the documentation with these links:)\n",
    "*   Dense()    [link text](https://keras.io/layers/core/) - Create a fully connected layer\n",
    "*   Conv2D()   [link text](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D/) - create a convolutional layer \n",
    "*   Pooling()  [link text](https://keras.io/layers/pooling/) - create a pooling layer \n",
    "*   Dropout()  [link text](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) - apply drop out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Baseline: a simple linear model\n",
    "As a first baseline, we will create a very simple, linear model consisting of one linear transformation matrix and train it with backpropagation.\n",
    "\n",
    "*  To create the model object, use the tf.keras.Sequential() function as shown here: https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential.\n",
    "Since we're not using convolutions for now, we can simply flatten all input pixels into a single row per image containing 28x28 pixel values.\n",
    "\n",
    "*  Then add a single, linear layer that maps all these pixels onto the 10 output classes. Since the outputs represent class probabilities we can use a softmax activation at the output of our model.\n",
    "\n",
    "*  You can print a description of your model using model.summary()\n",
    "\n",
    "Extra question: what does the softmax activation actually do? How does this affect our training procedure?\n",
    "Here is a good post explaining most of the details: https://medium.com/data-science-bootcamp/understand-the-softmax-function-in-minutes-f3a59641e86d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model:\n",
    "model = \n",
    "\n",
    "# Flatten all the pixels (You must define the input shape in the first layer of the neural network)\n",
    "\n",
    "# Add one Dense layer mapping all those pixels onto 10 output classes (add a softmax activation):\n",
    "\n",
    "# Take a look at the model summary:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FhxJ5dinZZg8"
   },
   "source": [
    "## Compile the model\n",
    "Configure the learning process with compile() API before training the model. It receives three arguments:\n",
    "\n",
    "*   An optimizer, we'll use adam\n",
    "*   A loss function, we'll use the 'categorical_crossentropy'\n",
    "*   A list of metrics, here we'll start with 'accuracy'\n",
    "\n",
    "See https://keras.io/models/model/ for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQUlOa8cZZg9"
   },
   "outputs": [],
   "source": [
    "#Compile the model:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DtOvh3YVZZg_"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Now let's train the model with fit() API.\n",
    "\n",
    "We use  the [ModelCheckpoint](https://keras.io/callbacks/#modelcheckpoint) API to save the model after every epoch. Set \"save_best_only = True\" to save only when the validation accuracy improves.\n",
    "\n",
    "You will also have to configure the batch-size and the number of epochs to train for.\n",
    "What do these words mean exactly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "colab_type": "code",
    "id": "ZTmapAttZZhA",
    "outputId": "08770dfd-10f0-4fad-81a6-0b0333086281"
   },
   "outputs": [],
   "source": [
    "import keras.callbacks\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "model.fit(##ToDo##)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-MGLwZQy05d"
   },
   "source": [
    "## Load Model with the best validation accuracy\n",
    "Use the .load_weights() function for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UD1tecxUZZhE"
   },
   "outputs": [],
   "source": [
    "# Load the weights with the best validation accuracy:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9RTRkan4yq5H"
   },
   "source": [
    "## Test Accuracy\n",
    "Since we used our validation set to choose the best model, we are implicitly already overfitting on this subset of the data. To get the final accuracy estimate our model would get on completely unseen data, compute the accuracy on the test set! Use the .evaluate() function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "VZtqBqFFy62R",
    "outputId": "7cc9a4dd-1641-4a94-f4ce-c209cf9a142d"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on test set, and print the accuracy you get:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJv7XEk10bOv"
   },
   "source": [
    "## Visualize prediction\n",
    "Now let's visualize the predictions from the model you just trained. \n",
    "First we get the predictions with the model from the test data.\n",
    "Then we visualize some images from the test data set, and set the titles with the prediction (and the groud truth label).\n",
    "If the prediction matches the true label, the title will be green; otherwise it's displayed in red.\n",
    "Package everything in a nice, callable function 'visualize_model_predictions(model, x, y)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "colab_type": "code",
    "id": "QwNmlfIC0YxM",
    "outputId": "dc74804f-8871-43a6-ea37-3ef4d57d413f"
   },
   "outputs": [],
   "source": [
    "def visualize_model_predictions(model_object, x, y):\n",
    "    ## ToDo ##\n",
    "        \n",
    "visualize_model_predictions(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Assignment:\n",
    "Visualise what this single, linear layer has learned to detect for each class by plotting the weights of trained network.\n",
    "Our transformation layer is a weight matrix of dimension [28x28, 10]. In a sense, it has learned a 'filter' for each of the 10 classes. Try to plot what these 10 filters look like, by reshaping them into 28x28 images and visualising the results for each class with matplotlib.imshow().\n",
    "\n",
    "To get the weight matrix of your trained model, you can use the model.layers and .get_weights() functions.\n",
    "\n",
    "## Extra Assignment 2:\n",
    "Compare the filters you just plotted with the average image for each class, do you notice any differences? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra assignment 3:\n",
    "Change the code in block 1.0 to work with MNIST instead of Fashion-MNIST (everything else can stay the same). Rerun all the code you've written so far.\n",
    "\n",
    "What Test-accuracy do you get with a simple, linear model? Can you see now why MNIST is gradually losing favor as a benchmarking dataset? What about the filter visualisations VS the average images, they look interesting right? Try to think about what exactly is going on here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Let's turn this into a real neural network!\n",
    "Add a single hidden layer to the model and add an activation function after that layer (eg 'relu').\n",
    "The number of hidden units in this layer is usually something in between the input dimension (28x28) and the output dimension (10). Play around with the activation function and the number of hidden units, how do they affect the models performance / training speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Flatten --> Dense_Relu --> Dense_Softmax:\n",
    "\n",
    "\n",
    "\n",
    "# Take a look at the model summary:\n",
    "model.summary()\n",
    "\n",
    "#Compile the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add a checkpointer and fit the model on the train data: (you have already done this, see above!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Load the best model (according to the validation set) and compute the test accuracy. Re-use your 'visuzalize_model_predictions()' function to display some results.\n",
    "\n",
    "**Extra question:** Why can't we also visualise the filters learned by this neural network with one hidden layer? What's the problem in this case? Notice how this gives rise to the whole \"interpretability\" problem in Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the best model:\n",
    "\n",
    "## Get test predictions:\n",
    "\n",
    "## Visualise some results:\n",
    "visualize_model_predictions(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8AehWdRAVKN5"
   },
   "source": [
    "## 2.2 Let's make our model Deeper! \n",
    "Add two extra hidden layers to start with.\n",
    "Explore the effects of adding more depth/width to your network, what happens to the number of trainable parameters?\n",
    "What about training speed, test-accuracy, ... Notice that there usually is a clear tradeoff between training-time and model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Define the model architecture:\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding callbacks\n",
    "Because we just made our model a lot deeper, it will have to train longer in order to use its full potential!\n",
    "But obviously, we don't want to keep training too long or we'll overfit.\n",
    "To get more info during training we'll add two extra callbacks to the model.fit() method that:\n",
    "1. Stop the model training loop if the validation loss keeps dropping consistently (eg 10 times in a row) (This is a default callback, available in Keras)\n",
    "2. Periodically visualise the validation error while training (This is a custom callback function you will have to create yourself)\n",
    "\n",
    "You can find more documentation here: https://keras.io/callbacks/ (For the custom callback, scroll down to \"Create a callback\" section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plot_train_progress(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        #Class attributes eg 'self.plot_frequency'\n",
    "        # ToDo\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.plot_frequency == 0:\n",
    "            #plot the training progress:\n",
    "            #ToDo\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.train_losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "# Early stopping callback:\n",
    "\n",
    "# Checkpointer callback:\n",
    "\n",
    "# Plot_train_progress callback:\n",
    "\n",
    "callbacks_list = [checkpointer, plot_train_progress_cb, earlyStopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=128,\n",
    "         epochs=25,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.weights.best.hdf5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test accuracy: %.2f%%' %(100*score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra:** To experiment and get some intuition as to why making the network deeper makes it easier to fit the data, you can experiment with this amazing in-browser tool: https://playground.tensorflow.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Convolutions \n",
    "### Lets add in some of the big guns in Computer Vision: Convolutions!\n",
    "\n",
    "Notice that up until now, we've always started our network with a Flatten() operation that basically throws away all the spatial dependency information in our image. Time to change that!\n",
    "\n",
    "Chain two Conv2D layers in the beginning of the network (remove the Flatten operation) and follow each one with a MaxPooling2D layer to downscale the resolution of the hidden representations. Finally add some normal FC layers to map the convolutional features to the output classes. (You will need to re-add a Flatten() operation for this).\n",
    "Play around with different architectures and keep track of the following variables:\n",
    "- Total number of trainable parameters in the network\n",
    "- Network depth (how many non-linear layers do I have that transform the data from pixel-space to label-space?)\n",
    "- Training time per epoch\n",
    "- Final accuracy after training for N epochs\n",
    "\n",
    "You can find the documentation for the Conv2D layers here: https://keras.io/layers/convolutional/\n",
    "\n",
    "**Extra question:** What does the MaxPooling2D operation do exactly? Do we lose any information in this step? What is good/bad about that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Define the model:\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Define the callbacks you want:\n",
    "\n",
    "callbacks_list = # ToDo\n",
    "\n",
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=128,\n",
    "         epochs=25,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.weights.best.hdf5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test accuracy: %.2f%%' %(100*score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra**:\n",
    "Run the visualize_model_predictions() function both on some examples from the training data and the test data, do you notice any differences? Is there an overall difference between the accuracy on the Train-set vs the Test-set? What is going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model_predictions(model, x_test, y_test)\n",
    "visualize_model_predictions(model, x_train, y_train)\n",
    "\n",
    "#Compute & compare train and test accuracies:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model currently has a lot of degrees of freedom (it has a LOT of trainable parameters and can therefore fit almost any function if we just keep training for long enough). This means our network is also prone to overfitting. \n",
    "\n",
    "In this section, let's add dropout layers between the main parts of our network to avoid overfitting.\n",
    "What is a good dropout rate?\n",
    "\n",
    "**Extra:** To get an idea of the degree to which these networks can overfit take a look at this amazing paper which shows that a large enough CNN can basically memorize a very large, random dataset: https://arxiv.org/abs/1611.03530\n",
    "\n",
    "**Extra:** Also try to add an L2 Regularization penalty to every layer in your network. What is a good setting of the multiplier constant? (see https://keras.io/regularizers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Define the model:\n",
    "\n",
    "# Take a look at the model summary\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "callbacks_list = # ToDo\n",
    "\n",
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=128,\n",
    "         epochs=25,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.weights.best.hdf5')\n",
    "\n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train accuracy: %.2f%% || Test accuracy: %.2f%%' %(100*train_score[1], 100*test_score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Data Augmentation\n",
    "In the real world, getting enough training data is often a problem. To show the effect of this, training your architecture from above using only 100 training images, what is the best test-accuracy you can get now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# You can use the previous model architecture:\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nr_samples_to_use = 100\n",
    "batch_size = 32\n",
    "\n",
    "callbacks_list = # Whatever you want to use\n",
    "\n",
    "model.fit(x_train[:nr_samples_to_use],\n",
    "         y_train[:nr_samples_to_use],\n",
    "         batch_size=batch_size,\n",
    "         epochs=50,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.weights.best.hdf5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test accuracy: %.2f%%' %(100*score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets augment our small Training-dataset at runtime using an ImageDataGenerator():\n",
    "See https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training:\n",
    "train_datagen = ImageDataGenerator( #ToDo )\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "validation_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "train_datagen.fit(x_train)\n",
    "validation_datagen.fit(x_valid)\n",
    "test_datagen.fit(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a few batches of augmented images to check the result of your Data Augmentation parameters\n",
    "Make sure you can still classify every augmented image yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the ImageDataGenerator to augment the small Train-subset at runtime.\n",
    "What test-accuracy do you get now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Use the same model as before\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "callbacks_list = # Up to you\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(generator = train_datagen.flow(x_train[:nr_samples_to_use], y_train[:nr_samples_to_use], batch_size=batch_size),\n",
    "                    validation_data = validation_datagen.flow(x_valid, y_valid, batch_size=batch_size), \n",
    "                    steps_per_epoch = nr_samples_to_use // batch_size,\n",
    "                    callbacks=callbacks_list,\n",
    "                    use_multiprocessing=True,\n",
    "                    workers=8,\n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model.weights.best.hdf5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test accuracy: %.2f%%' %(100*score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Data Augmentation on Fashion-MNIST is not the most effective. \n",
    "## But the concept is very generally usefull for a lot of Deep Learning problems, hence the inclusion here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final assignment\n",
    "### Finally, throw everything together and try to get the best possible performance on the Test-set! Who will win?\n",
    "\n",
    "For the Pro's, here are some additional tips:\n",
    "* Try Batch-Normalization layers\n",
    "* Play around with the Data Augmentation parameters a lot: augmenting data is good, but you don't want to push your training data distribution to far out (the test-data is not augmented!!) For example: sneakers, sandals and boots are always facing left in the Fashion-MNIST dataset, so random-horizontal flipping isn't the best option here...\n",
    "* You could also experiment with some of the newer activation functions like LeakyReLU, SeLU, ...\n",
    "* Cyclical learning rates\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "fashion_mnist_keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
